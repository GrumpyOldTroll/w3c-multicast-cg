Video: https://www.youtube.com/watch?v=VV4gbOczhkU
Slides: https://docs.google.com/presentation/d/1YAFs3Pif0o2e3hLdFbEnpm0iAC8NBPXuDBZKi2FTO6A/edit

Present: 

Discussion 1: 11m50s
  Eric: - sustainability +1
    - suggestion: get the same metric estimate value for video game downloads and video (instead of % of total carbon footprint for 1 vs. tonnes for the other)
    - it'd be good to educate the stakeholders on how much impact multicast would have
      - jake: did some of this with ISPs especially, gave them some data about offloadability for them.  Peak traffic especially interesting to the ISPs we spoke to (user experience angle), but energy usage savings likely come heavily from average/day-to-day usage.


Discussion 2: (24m)
  - how active are the browser vendors in IETF work so far?
    - jake: not very.  Ekr from Mozilla responded but was somewhat negative. In general browsers not yet interested.
  - Amazon involved?
    - jake: not at IETF.  Amazon did call to ask about multicast due to NFL TNF deal over next 10 years.  They are examining options.  We don't have a production implementation yet, but they are looking for a way to start next year.  They're supportive of the standards work, they may or may not be able to use it on the early side.  Also had conversations with some at Google, not everyone there is convinced.  A few have have privately expressed support, but have not publicly engaged.  Lots of people start out skeptical on multicas--ASM was a big false start that got a lot of burned fingers.  However, this means it's already widely deployed for some purposes and is in active use in many networks, but not for global interdomain traffic.
  - Eric: first task for CG is to articulate pain points and business prop for stakeholders.  CG should be engaging them and gaining support.  Youtube would be a natural supporter, Amazon as well.  Need to get them to feel the pain points and get them interested in this, and the other one is how to get the Chrome people comfortable with the security story
    - jake: there's a chicken and egg problem here.  If the technical capability is actually executable, this raises interest level.  The slideware demos are unconvincing, especially given multicast history.
      - Eric: can you get the ISPs involved here?
      - jake: a few have joined the group, mostly haven't really dug in yet.  Some are members, but are only tangentially interested in the browser work, they just want it to be there.  I'd love to have a big-picture plan in place that works well.  The multicast-cg is about getting the browser in shape, but some of this has to happen outside standards bodies.
      - Eric: It's a good point, the business people have to drive the standards.  My big concern here is that business won't adopt, that has to be the immediate challenge to address.  The benefits are quite obvious, but how do we as a group rally the ecosystem around it?
      - jake: this is why I was engaging with demos, and why my next steps are getting the demos closer to releasable.  Having a browser fork that does something useful is to me one of the key next steps to make the case that we can do something real here that people will believe.  And a key piece of that is the browser tech side, particularly the security.  It has to be a credible proposal for the browser people to pay attention.  Right now, yes it can play video but not in a way that can be accepted into browsers, and if we can get it to where it could be, with growing consensus that it's workable, that would make it more likely for browsers to become interested.  But you're right, this is just a hope, and we're missing the buy-in we need, even from people who have a lot to gain here.  Our analysis says there's a lot of money to be saved here, we think the low interest is because people don't think it's credible until they spend effort looking at it for real, but not sure.
    - Dominique: interesting challenge to coordinate the challenges.  Part o the conversation that might be needed would be bound to the timeline.  What's your best guess on the time needed to align the stars?  Like the demo, how long before the browser is operational, and then how long to go door to door and convince people?
      - jake: you probably shouldn't trust my estimate.  I thought I had a demo running, so I thought I'd be done by now.
      - dom: so what I'm hearing is that in your plan, the security obstacle is a key one to lift to give confidence we can build momentum across stakeholders--once you have something you can convince a browser to ship, then you have something you can convince at least one ISP and one content owner to use, and then you'd build steam
      - jake: basically, yes.  There's a few other rays of hope, for instance geant and internet2 have some interdomain multicast delivery today, and on both their timelines are deploying some ingest platform instances to pull in multicast and distribute it, which is a big part of what the ISP lab tests were doing.  There's several moving parts here, some of which are outside the w3c charter, but are critical to the ultimate success here.  So in this CG, I was hoping to move forward the receiver distribution side of this story, but I do encourage people to engage in IETF as well.
    - Gang: question: customers want this if it's transparent.  In DVB, they do this thru an mpeg-dash player, and they don't seem to have the same complex security model problem.  Here we seem to need to manage the source and the encryption on each multicast stream.  Can we do this on the server side instead in an edge server?  Won't this help with the last mile bandwidth issue?  If we do it from the edge server doesn't it simplify the security problem?
      - Jake: If you're making use of the broadcast capability at the edge that way, you're trusting the edge servers.  There's been a history of abuses like ad-theft, when you send stuff an ISP can change on the way.  That's actually the way it works today in the broadcast tv world because you can't get the scale, but there's a gap on security considerations for doing this transparently.  The current proposal addresses this with AMBI, which makes it impossible to do unauthenticated injection in a way not done with the handoff model.  The idea that the broadcast part happens inside the walled-gardens is possible to make some of this happen, but then you have new problems, which is that each use case needs a separate set of specs.  If you standardize on video, you won't get VR or downloads.  It's possible to do it separately for those, but then you still have trouble--4g had this capability and nobody used it, the northbound interfaces were challenging.
      - Gang: yes, but there's an incentive for the ISP to make a change since it'll save them bandwidth.  It's easier to make the change from the ISP position
      - jake: I think the way we've proposed is the easier way for the ISP, they don't have content to manage that they have to be the source of, and own the send/receive and the protocols those use.  But yes, this is one of the big design questions, should it be only the end isp is the one that can broadcast and you have to give it to them as an object they can unpack and distribute, or is there a way to do this as opaque multicast packets they can just stream through?  People have different opinions, mine is that we should do packet streaming.  Most of the ISPs we've talked to tend to prefer this moel because they don't have as much to maintain, because they can focus on deelivring packets, without having to maintain user applications, and things that work with some content but not others, they can just standardize on ip transport, which brings it closer to the way http works.  But yes, great question, and opinions sometimes differ.



